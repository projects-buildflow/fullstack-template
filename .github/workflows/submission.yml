name: Task Submission

on:
  pull_request:
    types: [opened, synchronize, reopened]

env:
  NODE_VERSION: "20"

jobs:
  # ============================================
  # Job 1: Detect task and validate
  # ============================================
  setup:
    name: Setup & Validate
    runs-on: ubuntu-latest
    outputs:
      task_id: ${{ steps.detect.outputs.task_id }}
      week: ${{ steps.detect.outputs.week }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect task from branch name
        id: detect
        run: |
          BRANCH="${{ github.head_ref }}"
          echo "Branch: $BRANCH"

          # Extract task ID - flexible matching for patterns like:
          # task-1.2, task-1.2-feature, 1.2-my-branch, feature/1.2, etc.
          TASK_ID=$(echo "$BRANCH" | grep -oP '\d+\.\d+' | head -1 || echo "")

          if [ -z "$TASK_ID" ]; then
            echo "::warning::Could not detect task number from branch: $BRANCH"
            echo "::warning::Branch should contain a task number like 1.2 or 2.1"
            echo "task_id=" >> $GITHUB_OUTPUT
            echo "week=" >> $GITHUB_OUTPUT
          else
            # Get week number
            WEEK=$(echo "$TASK_ID" | cut -d'.' -f1)
            echo "task_id=$TASK_ID" >> $GITHUB_OUTPUT
            echo "week=$WEEK" >> $GITHUB_OUTPUT
            echo "Detected: Task=$TASK_ID, Week=$WEEK"
          fi

      - name: Validate branch has task number
        run: |
          TASK_ID="${{ steps.detect.outputs.task_id }}"
          if [ -z "$TASK_ID" ]; then
            echo "::error::Branch name must contain a task number (e.g., 1.2)"
            echo ""
            echo "Valid branch name examples:"
            echo "  - task-1.2"
            echo "  - task-1.2-my-feature"
            echo "  - 1.2-add-button"
            echo ""
            echo "Your branch: ${{ github.head_ref }}"
            exit 1
          fi

  # ============================================
  # Job 2: Linting
  # ============================================
  lint:
    name: Lint Code
    runs-on: ubuntu-latest
    needs: setup

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run ESLint
        id: eslint
        continue-on-error: true
        run: |
          npm run lint 2>&1 | tee lint-output.txt || echo "eslint_failed=true" >> $GITHUB_OUTPUT

      - name: Lint summary
        run: |
          if [[ "${{ steps.eslint.outputs.eslint_failed }}" == "true" ]]; then
            echo "::warning::Linting issues found. Please fix them."
            echo ""
            echo "To fix issues, run: npm run lint -- --fix"
            exit 1
          fi
          echo "Linting passed"

  # ============================================
  # Job 3: Run Tests
  # ============================================
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: setup
    outputs:
      passed: ${{ steps.test.outputs.passed }}
      test_score: ${{ steps.test.outputs.test_score }}
      failed_tests: ${{ steps.failures.outputs.failed_tests }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run task tests
        id: test
        run: |
          TASK_ID="${{ needs.setup.outputs.task_id }}"

          # Convert task ID to test file name (2.1 -> task_2_1.test.ts or task_2_1.test.tsx)
          TEST_FILE_TS="__tests__/task_${TASK_ID//./_}.test.ts"
          TEST_FILE_TSX="__tests__/task_${TASK_ID//./_}.test.tsx"

          echo "Looking for test files: $TEST_FILE_TS or $TEST_FILE_TSX"

          if [ ! -f "$TEST_FILE_TS" ] && [ ! -f "$TEST_FILE_TSX" ]; then
            echo "No test file found for task $TASK_ID"
            echo "passed=skip" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Determine which test file exists
          if [ -f "$TEST_FILE_TS" ]; then
            TEST_FILE="$TEST_FILE_TS"
          else
            TEST_FILE="$TEST_FILE_TSX"
          fi

          echo "Running tests from: $TEST_FILE"

          # Run Vitest for specific test file, capture exit code
          set +e
          npm run test:run -- "$TEST_FILE" --reporter=verbose 2>&1 | tee test-output.txt
          TEST_EXIT_CODE=${PIPESTATUS[0]}
          set -e

          # Always set the output before potentially failing
          if [ $TEST_EXIT_CODE -eq 0 ]; then
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "test_score=100" >> $GITHUB_OUTPUT
            echo "✅ All tests passed!"
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "test_score=0" >> $GITHUB_OUTPUT
            echo "❌ Some tests failed. Please fix them before merging."
          fi

          # Exit with the test result so the job properly fails
          exit $TEST_EXIT_CODE

      - name: Extract failed test details
        id: failures
        if: always()
        run: |
          if [ -f test-output.txt ]; then
            FAILED_TESTS=$(node -e "
          const fs = require('fs');
          const lines = fs.readFileSync('test-output.txt', 'utf8').split('\n');
          const failures = [];
          for (let i = 0; i < lines.length; i++) {
            const line = lines[i];
            if (line.includes('×') || (line.includes('FAIL') && line.includes('>'))) {
              const name = line.replace(/[×✗]/g, '').replace(/.*>/, '').trim();
              let error = '';
              for (let j = i + 1; j < Math.min(i + 5, lines.length); j++) {
                const l = lines[j].trim();
                if (l.startsWith('Error') || l.startsWith('Assertion') || l.startsWith('expect')) {
                  error = l.substring(0, 200);
                  break;
                }
              }
              if (name) failures.push({name, error});
            }
          }
          console.log(JSON.stringify(failures.slice(0, 10)));
          " 2>/dev/null || echo "[]")
            echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
          else
            echo "failed_tests=[]" >> $GITHUB_OUTPUT
          fi

      - name: Upload test output
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-output
          path: test-output.txt
          if-no-files-found: ignore

  # ============================================
  # Job 4: Notify Backend (triggers AI review if needed)
  # ============================================
  notify:
    name: Notify Backend
    runs-on: ubuntu-latest
    needs: [setup, lint, test]
    if: always()

    steps:
      - name: Send results to backend
        env:
          BACKEND_URL: ${{ secrets.BACKEND_URL }}
          WEBHOOK_SECRET: ${{ secrets.WEBHOOK_SECRET }}
          FAILED_TESTS: ${{ needs.test.outputs.failed_tests }}
          RAW_TEST_PASSED: ${{ needs.test.outputs.passed }}
          RAW_TEST_SCORE: ${{ needs.test.outputs.test_score }}
          RAW_LINT_PASSED: ${{ needs.lint.result == 'success' }}
        run: |
          if [ -z "$BACKEND_URL" ]; then
            echo "BACKEND_URL not configured, skipping notification"
            exit 0
          fi

          # Determine overall status
          LINT_PASSED="$RAW_LINT_PASSED"
          TEST_PASSED="$RAW_TEST_PASSED"
          TEST_SCORE="$RAW_TEST_SCORE"

          # Convert skip to false — no test file means not passing
          if [ "$TEST_PASSED" = "skip" ] || [ -z "$TEST_PASSED" ]; then
            TEST_PASSED="false"
            TEST_SCORE="0"
          fi

          if [ -z "$FAILED_TESTS" ]; then
            FAILED_TESTS="[]"
          fi

          # Use jq to safely construct JSON (handles special chars in failed_tests)
          PAYLOAD=$(jq -n \
            --arg event "pr_check_complete" \
            --argjson pr_number "${{ github.event.pull_request.number }}" \
            --arg pr_url "${{ github.event.pull_request.html_url }}" \
            --arg task_id "${{ needs.setup.outputs.task_id }}" \
            --arg student_github "${{ github.event.pull_request.user.login }}" \
            --arg branch_name "${{ github.head_ref }}" \
            --argjson lint_passed "$LINT_PASSED" \
            --arg test_passed "$TEST_PASSED" \
            --argjson test_score "${TEST_SCORE:-0}" \
            --arg repo "${{ github.repository }}" \
            --arg track "fullstack" \
            --argjson failed_tests "$FAILED_TESTS" \
            '{
              event: $event,
              pr_number: $pr_number,
              pr_url: $pr_url,
              task_id: $task_id,
              student_github: $student_github,
              branch_name: $branch_name,
              lint_passed: $lint_passed,
              test_passed: $test_passed,
              test_score: $test_score,
              repo: $repo,
              track: $track,
              failed_tests: $failed_tests
            }')

          curl -X POST "${BACKEND_URL}/webhooks/github" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer ${WEBHOOK_SECRET}" \
            -d "$PAYLOAD" || echo "Backend notification failed (non-fatal)"

          echo "Backend notified"
